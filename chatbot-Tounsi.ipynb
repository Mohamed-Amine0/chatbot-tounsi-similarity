{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a2a535",
   "metadata": {},
   "source": [
    "# Importation des modules n√©cessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a34dd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatterbot import ChatBot\n",
    "from chatterbot.trainers import ListTrainer\n",
    "from cleaner import clean_corpus\n",
    "from weather import get_weather\n",
    "from wikipediaprocess import search_wikipedia\n",
    "from newsapi import NewsApiClient\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105bed87",
   "metadata": {},
   "source": [
    "# Initialisation de l'API de news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4bfd91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsapi = NewsApiClient(api_key='a1d8789da28b4df282afbabff793c211')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fc15d0",
   "metadata": {},
   "source": [
    "# Initialisation du chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5f1298c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Mohamed-Amine-\n",
      "[nltk_data]     Miladi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Mohamed-Amine-\n",
      "[nltk_data]     Miladi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Mohamed-Amine-\n",
      "[nltk_data]     Miladi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "chatbot = ChatBot(\"Chatbot tounsi\",logic_adapters=[      \n",
    "    # Adapter pour √©valuer des expressions math√©matiques\n",
    "    {\n",
    "        'import_path': 'chatterbot.logic.MathematicalEvaluation',\n",
    "    },\n",
    "    # Adapter pour trouver la meilleure r√©ponse en fonction du contexte\n",
    "    {\n",
    "        'import_path': 'chatterbot.logic.BestMatch',\n",
    "    }\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9645ca7",
   "metadata": {},
   "source": [
    "# Fichier contenant la conversation √† utiliser pour entra√Æner le chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c08e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_FILE=\"chat2.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04e9f67",
   "metadata": {},
   "source": [
    "# Entra√Ænement du chatbot sur le fichier de corpus nettoy√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58b7e86a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Trainer: [####################] 100%\n"
     ]
    }
   ],
   "source": [
    "trainer = ListTrainer(chatbot)\n",
    "cleaned_corpus=clean_corpus(CORPUS_FILE)\n",
    "trainer.train(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef477f38",
   "metadata": {},
   "source": [
    "# Cr√©er une liste de phrases nettoy√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55423098",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(cleaned_corpus[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d25bb5",
   "metadata": {},
   "source": [
    "# Conditions pour quitter le chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "501dff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_conditions = (\":q\", \"quit\", \"exit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916cbb82",
   "metadata": {},
   "source": [
    "# Ex√©cution du ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb0c4ce2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Pour obtenir la m√©t√©o d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les derni√®res actualit√©s sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la d√©finition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> cv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed-Amine-Miladi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Cv hamdoullah\n",
      "*********************************************************\n",
      "Pour obtenir la m√©t√©o d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les derni√®res actualit√©s sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la d√©finition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> chesmek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed-Amine-Miladi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Esmi chatbot tounsi\n",
      "*********************************************************\n",
      "Pour obtenir la m√©t√©o d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les derni√®res actualit√©s sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la d√©finition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> tcodi?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed-Amine-Miladi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Ey tawa hehda klem ?\n",
      "*********************************************************\n",
      "Pour obtenir la m√©t√©o d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les derni√®res actualit√©s sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la d√©finition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> chnowa ta9s fi Tunis\n",
      "ta9s: ü§ñFi Tunis aana temperature :22.9 ¬∞C wel humidit√© : 25%.\n",
      "*********************************************************\n",
      "Pour obtenir la m√©t√©o d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les derni√®res actualit√©s sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la d√©finition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> wiki Abidjan\n",
      "ü§ñŸÜÿßÿØŸä ÿ£ÿ≥ŸäŸÉ ŸÖŸäŸÖŸàÿ≥ÿß (ÿ®ÿßŸÑŸÅÿ±ŸÜÿ≥Ÿäÿ©: ASEC Mimosas)‚Äè ŸáŸà ŸÜÿßÿØŸä ŸÉÿ±ÿ© ŸÇÿØŸÖ ŸÖŸÜ ÿ≥ÿßÿ≠ŸÑ ÿßŸÑÿπÿßÿ¨ ÿ™ÿ£ÿ≥ÿ≥ ÿ≥ŸÜÿ© 1948. Ÿäÿπÿ™ÿ®ÿ± ŸÖŸÜ ÿ®ŸäŸÜ ÿßŸÑŸÜŸàÿßÿØŸä ÿßŸÑŸÉÿ®Ÿäÿ±ÿ© ÿπŸÑŸâ ŸÖÿ≥ÿ™ŸàŸâ ŸÉÿ±ÿ© ÿßŸÑŸÇÿØŸÖ ŸÅŸä ÿ≥ÿßÿ≠ŸÑ ÿßŸÑÿπÿßÿ¨ ŸàŸÖŸÜ ÿ®ŸäŸÜ ÿ£ŸÉÿ´ÿ± ÿßŸÑÿßŸÜÿØŸäÿ© ÿ™ŸÖÿ´ŸäŸÑÿß ŸÑÿ≥ÿßÿ≠ŸÑ ÿßŸÑÿπÿßÿ¨ ŸÅŸä ŸÖÿ≥ÿßÿ®ŸÇÿ© ÿØŸàÿ±Ÿä ÿ£ÿ®ÿ∑ÿßŸÑ ÿ£ŸÅÿ±ŸäŸÇŸäÿß ÿ•ŸÑŸâ ÿ¨ÿßŸÜÿ® ŸÜÿßÿØŸâ ÿ£ŸÅÿ±ŸäŸÉÿß ÿ≥ÿ®Ÿàÿ±ÿ™ÿ≥ÿå ŸàŸäŸÑÿπÿ® ŸÅŸä ÿØŸàÿ±Ÿä ÿßŸÑÿØÿ±ÿ¨ÿ© ÿßŸÑŸÖŸÖÿ™ÿßÿ≤ÿ©.\n",
      "*********************************************************\n",
      "Pour obtenir la m√©t√©o d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les derni√®res actualit√©s sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la d√©finition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> wiki ŸÇÿ∑ÿ±\n",
      "ü§ñŸÇŸéÿ∑Ÿéÿ±Ÿí ÿ£Ÿà (ÿ±ÿ≥ŸÖŸäÿßŸã: ÿØŸéŸàŸíŸÑŸéÿ©Ÿè ŸÇŸéÿ∑Ÿéÿ±Ÿí)ÿå ŸáŸä ÿØŸàŸÑÿ© ÿπÿ±ÿ®Ÿäÿ© ÿÆŸÑŸäÿ¨Ÿäÿ© ÿ™ŸÇÿπ ŸÅŸä ÿ¥ÿ±ŸÇ ÿ¥ÿ®Ÿá ÿßŸÑÿ¨ÿ≤Ÿäÿ±ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ŸÅŸä ÿ¨ŸÜŸàÿ® ÿ∫ÿ±ÿ® ÿ¢ÿ≥Ÿäÿß ŸÖÿ∑ŸÑŸëÿ© ÿπŸÑŸâ ÿßŸÑÿÆŸÑŸäÿ¨ ÿßŸÑÿπÿ±ÿ®Ÿä ŸàÿπÿßÿµŸÖÿ™Ÿáÿß ÿßŸÑÿØŸàÿ≠ÿ©. ŸÑŸáÿß ÿ≠ÿØŸàÿØ ÿ®ÿ±Ÿäÿ© ŸÖÿ¥ÿ™ÿ±ŸÉÿ© ŸÖŸÜ ÿßŸÑÿ¨ŸÜŸàÿ® ŸÖÿπ ÿßŸÑŸÖŸÖŸÑŸÉÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿßŸÑÿ≥ÿπŸàÿØŸäÿ© Ÿàÿ®ÿ≠ÿ±Ÿäÿ© ŸÖÿπ ÿØŸàŸÑÿ© ÿßŸÑÿ•ŸÖÿßÿ±ÿßÿ™ ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿßŸÑŸÖÿ™ÿ≠ÿØÿ©ÿå ŸÖŸÖŸÑŸÉÿ© ÿßŸÑÿ®ÿ≠ÿ±ŸäŸÜ.\n",
      "*********************************************************\n",
      "Pour obtenir la m√©t√©o d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les derni√®res actualit√©s sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la d√©finition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> e5er a5bar aala Trump\n",
      "ÿ™ÿ±ÿßŸÖÿ® ŸäÿµŸÑ ÿ•ŸÑŸâ ŸÖÿ≠ŸÉŸÖÿ© ŸÖÿßŸÜŸáÿßÿ™ŸÜ ÿ≠Ÿäÿ´ ŸäŸÖÿ´ŸÑ ÿ£ŸÖÿßŸÖ ÿßŸÑŸÇÿ∂ÿßÿ° ŸÅŸä ÿ≥ÿßÿ®ŸÇÿ© ÿ™ÿßÿ±ŸäÿÆŸäÿ©\n",
      "ÿ®ÿπÿØ ÿ™Ÿàÿ¨ŸäŸá 34 ÿßÿ™ŸáÿßŸÖÿß ÿ¨ŸÜÿßÿ¶Ÿäÿß ŸÑŸá‚Ä¶ ŸÖÿß ŸáŸà ŸÖÿ≥ÿ™ŸÇÿ®ŸÑ ÿ™ÿ±ÿßŸÖÿ® ŸÇÿßŸÜŸàŸÜŸäÿß Ÿàÿ≥Ÿäÿßÿ≥Ÿäÿßÿü\n",
      "ÿ™ÿ±ÿßŸÖÿ® ŸÇÿ®ŸÑ ŸÖÿ≠ÿßŸÉŸÖÿ™Ÿá: ŸÑÿß ŸäŸÖŸÉŸÜŸáŸÖ ÿ¥ÿ±ÿßÿ¶Ÿä Ÿàÿ£ŸÖÿ±ŸäŸÉÿß ÿ£ÿµÿ®ÿ≠ÿ™ ÿØŸàŸÑÿ© ŸÖŸÜ ÿßŸÑÿπÿßŸÑŸÖ ÿßŸÑÿ´ÿßŸÑÿ´... ŸÅŸäÿØŸäŸà\n",
      "*********************************************************\n",
      "Pour obtenir la m√©t√©o d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les derni√®res actualit√©s sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la d√©finition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> :q\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Affichage des instructions pour l'utilisateur\n",
    "    print(\"*********************************************************\\nPour obtenir la m√©t√©o d'un pays, tapez : chnowa ta9s fi + nom du pays\\nPour obtenir les derni√®res actualit√©s sur un sujet, tapez : e5er a5bar aala + sujet\\nPour obtenir la d√©finition d'un sujet, tapez : wiki + sujet\\nPour quitter, tapez : quit ou exit\\n************************************************************\")\n",
    "    # Lecture de l'entr√©e utilisateur\n",
    "    query = input(\"> \")\n",
    "    # V√©rification si l'utilisateur veut quitter\n",
    "    if query in exit_conditions:\n",
    "        break\n",
    "    # R√©cup√©ration de la m√©t√©o pour un pays donn√©\n",
    "    elif query.startswith(\"chnowa ta9s fi \"):\n",
    "        # R√©cup√©ration du nom du pays\n",
    "        country = query.replace(\"chnowa ta9s fi \", \"\")\n",
    "        # R√©cup√©ration de la m√©t√©o pour le pays\n",
    "        weather = get_weather(country)\n",
    "        print(f\"ta9s: {weather}\")\n",
    "    # Recherche de la d√©finition d'un sujet donn√© sur Wikipedia\n",
    "    elif query.startswith(\"wiki \"):\n",
    "        topic=query.replace(\"wiki \",\"\")\n",
    "        wiki=search_wikipedia(topic)\n",
    "        print(wiki)\n",
    "    # R√©cup√©ration des derni√®res actualit√©s sur un sujet donn√©\n",
    "    elif query.startswith(\"e5er a5bar aala \"):\n",
    "        # R√©cup√©ration du sujet\n",
    "        theme=query.replace(\"e5er a5bar aala \",\"\")\n",
    "        # R√©cup√©ration des derni√®res actualit√©s\n",
    "        top_headlines = newsapi.get_everything(q=theme, sort_by='relevancy',language='ar')\n",
    "        for article in top_headlines['articles']:\n",
    "            print(article['title'])\n",
    "    # Si aucune des commandes ci-dessus n'a √©t√© reconnue, le chatbot tente de r√©pondre\n",
    "    else:\n",
    "        #print(f\"ü§ñ {str(chatbot.get_response(query))}\")\n",
    "\n",
    "        # Ajouter le prompt √† la liste des phrases\n",
    "        sentences.append(query)\n",
    "        \n",
    "        # Initialiser le vecteur TfidfVectorizer pour extraire les caract√©ristiques des phrases\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        \n",
    "        # Cr√©er une matrice Tfidf √† partir des phrases\n",
    "        tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "        \n",
    "        # Convertir la matrice en liste de listes\n",
    "        tfidf_list = tfidf_matrix.todense().tolist()\n",
    "        \n",
    "        # Cr√©er un DataFrame pandas √† partir de la liste de listes\n",
    "        df = pd.DataFrame(tfidf_list, columns=vectorizer.get_feature_names())\n",
    "        \n",
    "        # Calculer la similarit√© cosinus entre le prompt et chaque phrase dans la matrice\n",
    "        cosine_similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])\n",
    "        \n",
    "        # Trier les similarit√©s cosinus dans l'ordre d√©croissant\n",
    "        similarity_list = cosine_similarities.flatten()\n",
    "        index = similarity_list.argsort()[::-1]\n",
    "        \n",
    "        # Trouver l'entr√©e de corpus la plus similaire\n",
    "        most_similar_sentence = sentences[index[0]+1]\n",
    "        \n",
    "        # Ajouter la r√©ponse √† la liste des phrases\n",
    "        sentences.append(most_similar_sentence)\n",
    "        \n",
    "        # Afficher la r√©ponse la plus similaire\n",
    "        print(f\"ü§ñ {str(most_similar_sentence)}\")   \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
