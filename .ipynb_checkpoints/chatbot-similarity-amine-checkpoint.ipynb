{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a2a535",
   "metadata": {},
   "source": [
    "# Importation des modules n√©cessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a34dd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatterbot import ChatBot\n",
    "from chatterbot.trainers import ListTrainer\n",
    "from cleaner import clean_corpus\n",
    "from weather import get_weather\n",
    "from wikipediaprocess import search_wikipedia\n",
    "from newsapi import NewsApiClient\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105bed87",
   "metadata": {},
   "source": [
    "# Initialisation de l'API de news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4bfd91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsapi = NewsApiClient(api_key='a1d8789da28b4df282afbabff793c211')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fc15d0",
   "metadata": {},
   "source": [
    "# Initialisation du chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5f1298c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Mohamed-Amine-\n",
      "[nltk_data]     Miladi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Mohamed-Amine-\n",
      "[nltk_data]     Miladi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Mohamed-Amine-\n",
      "[nltk_data]     Miladi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "chatbot = ChatBot(\"Chatbot tounsi\",logic_adapters=[      \n",
    "    # Adapter pour √©valuer des expressions math√©matiques\n",
    "    {\n",
    "        'import_path': 'chatterbot.logic.MathematicalEvaluation',\n",
    "    },\n",
    "    # Adapter pour trouver la meilleure r√©ponse en fonction du contexte\n",
    "    {\n",
    "        'import_path': 'chatterbot.logic.BestMatch',\n",
    "    }\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9645ca7",
   "metadata": {},
   "source": [
    "# Fichier contenant la conversation √† utiliser pour entra√Æner le chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c08e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_FILE=\"chat2.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04e9f67",
   "metadata": {},
   "source": [
    "# Entra√Ænement du chatbot sur le fichier de corpus nettoy√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58b7e86a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Trainer: [####################] 100%\n"
     ]
    }
   ],
   "source": [
    "trainer = ListTrainer(chatbot)\n",
    "cleaned_corpus=clean_corpus(CORPUS_FILE)\n",
    "trainer.train(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48a777b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://play.mobilelegends.com/events/halloweencards/?Yz00WVdzMUtYSnJaMkZhb09WYUdhWFU1RldxZEhTeUh2SldaNkdhcE5va3BscVo1dG1oN0VOJm89d2hhdHNhcHA=',\n",
       " 'Ahla bik',\n",
       " 'Salut',\n",
       " 'Winek cv?',\n",
       " 'Cv hamdoullah',\n",
       " 'Wenti?',\n",
       " 'Labes labes',\n",
       " 'Chkoun aandek a7sen jam3eya mtaa foot?',\n",
       " 'Real madrid wenti?',\n",
       " 'Bayern',\n",
       " 'Behi ta9s lyoum?',\n",
       " 'Ey behi',\n",
       " 'Samili 3 bolden yabdew bel T',\n",
       " 'Tunisie, Tanzanie Tchad',\n",
       " 'Maalem bravoüëè',\n",
       " 'Merciü•∞',\n",
       " 'Messi wala ronaldo?',\n",
       " 'Ronaldo',\n",
       " 'Bresil wala almania?',\n",
       " 'Bresil fel koora Almania fel 3icha üòâ',\n",
       " 'Pizza wala lasagna',\n",
       " 'Pizzaaaa üçïüçïüçïüçï',\n",
       " 'Capitale mta tunisie chnowa?',\n",
       " 'Tunis',\n",
       " 'üëè',\n",
       " 'Ch9awlek fel fst ka fac?',\n",
       " 'A9wa fac fi tounes',\n",
       " 'Akther bled t7eb temchilha ?',\n",
       " 'Autriche ma7leha‚ù§ te3jebni barcha',\n",
       " 'Mchit Paris 9bal?',\n",
       " 'Non ma mchitech',\n",
       " 'A7sen repas tounsi aandek?',\n",
       " 'Chorba frik w kafteji',\n",
       " 'Chnowa rayek fel AI?',\n",
       " 'Ai heya lmosta9bel',\n",
       " 'Ai bech te7tal el 3allem',\n",
       " 'A9wa film tfrajet fih ?',\n",
       " 'Ye3bouni aflem fima batman w lord of the rings',\n",
       " 'Taaref tcodi?',\n",
       " 'Ey tawa hehda klem ?',\n",
       " 'A7kili nokta',\n",
       " 'Fech testana men cha3b ychouf darhom mnadhma yes2elhom : ye5i chkoun jey hahaha',\n",
       " 'A7kili nokta',\n",
       " 'Fam djeja ordhet bes5ana ye5i jebet aadhma masmouta',\n",
       " 'A7kili nokta',\n",
       " 'We7ed mbala3 fel embouteillage double mara loula..double marra thenya ye5i tardouh üòÇ',\n",
       " 'Fi tounes fa9at tal9a we7ed aandou monguela ,kif tes2lou aal wa9t yejbed telifounou üòÜ',\n",
       " 'Nokta o5ra',\n",
       " 'Fama We7ed kathrelha mel torbia may7el frigidaire ken ma ydo9 lbeb',\n",
       " 'Chnowa aasmet libya?',\n",
       " 'Tripoli',\n",
       " 'Chesmek ?',\n",
       " 'Esmi chatbot tounsi',\n",
       " 'Aya n5alik sadi9i',\n",
       " 'Bye',\n",
       " 'Beslema')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef477f38",
   "metadata": {},
   "source": [
    "# Cr√©er une liste de phrases nettoy√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55423098",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = cleaned_corpus[1:]\n",
    "sentences = list(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8413a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5d25bb5",
   "metadata": {},
   "source": [
    "# Conditions pour quitter le chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "501dff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_conditions = (\":q\", \"quit\", \"exit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916cbb82",
   "metadata": {},
   "source": [
    "# Ex√©cution du ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb0c4ce2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Pour obtenir la m√©t√©o d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les derni√®res actualit√©s sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la d√©finition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> cv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed-Amine-Miladi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Cv hamdoullah\n",
      "*********************************************************\n",
      "Pour obtenir la m√©t√©o d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les derni√®res actualit√©s sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la d√©finition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> tcodi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed-Amine-Miladi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Ey tawa hehda klem ?\n",
      "*********************************************************\n",
      "Pour obtenir la m√©t√©o d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les derni√®res actualit√©s sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la d√©finition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> chnowa ta9s fi Tunis\n",
      "ta9s: ü§ñFi Tunis aana temperature :21.1 ¬∞C wel humidit√© : 55%.\n",
      "*********************************************************\n",
      "Pour obtenir la m√©t√©o d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les derni√®res actualit√©s sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la d√©finition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> e5er a5bar aala Trump\n",
      "ÿ™ÿ±ÿßŸÖÿ® ŸäÿµŸÑ ÿ•ŸÑŸâ ŸÖÿ≠ŸÉŸÖÿ© ŸÖÿßŸÜŸáÿßÿ™ŸÜ ÿ≠Ÿäÿ´ ŸäŸÖÿ´ŸÑ ÿ£ŸÖÿßŸÖ ÿßŸÑŸÇÿ∂ÿßÿ° ŸÅŸä ÿ≥ÿßÿ®ŸÇÿ© ÿ™ÿßÿ±ŸäÿÆŸäÿ©\n",
      "ÿ®ÿπÿØ ÿ™Ÿàÿ¨ŸäŸá 34 ÿßÿ™ŸáÿßŸÖÿß ÿ¨ŸÜÿßÿ¶Ÿäÿß ŸÑŸá‚Ä¶ ŸÖÿß ŸáŸà ŸÖÿ≥ÿ™ŸÇÿ®ŸÑ ÿ™ÿ±ÿßŸÖÿ® ŸÇÿßŸÜŸàŸÜŸäÿß Ÿàÿ≥Ÿäÿßÿ≥Ÿäÿßÿü\n",
      "ÿ™ÿ±ÿßŸÖÿ® ŸÇÿ®ŸÑ ŸÖÿ≠ÿßŸÉŸÖÿ™Ÿá: ŸÑÿß ŸäŸÖŸÉŸÜŸáŸÖ ÿ¥ÿ±ÿßÿ¶Ÿä Ÿàÿ£ŸÖÿ±ŸäŸÉÿß ÿ£ÿµÿ®ÿ≠ÿ™ ÿØŸàŸÑÿ© ŸÖŸÜ ÿßŸÑÿπÿßŸÑŸÖ ÿßŸÑÿ´ÿßŸÑÿ´... ŸÅŸäÿØŸäŸà\n",
      "*********************************************************\n",
      "Pour obtenir la m√©t√©o d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les derni√®res actualit√©s sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la d√©finition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> film ?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed-Amine-Miladi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Ye3bouni aflem fima batman w lord of the rings\n",
      "*********************************************************\n",
      "Pour obtenir la m√©t√©o d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les derni√®res actualit√©s sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la d√©finition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> bye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed-Amine-Miladi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Beslema\n",
      "*********************************************************\n",
      "Pour obtenir la m√©t√©o d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les derni√®res actualit√©s sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la d√©finition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> :q\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Affichage des instructions pour l'utilisateur\n",
    "    print(\"*********************************************************\\nPour obtenir la m√©t√©o d'un pays, tapez : chnowa ta9s fi + nom du pays\\nPour obtenir les derni√®res actualit√©s sur un sujet, tapez : e5er a5bar aala + sujet\\nPour obtenir la d√©finition d'un sujet, tapez : wiki + sujet\\nPour quitter, tapez : quit ou exit\\n************************************************************\")\n",
    "    # Lecture de l'entr√©e utilisateur\n",
    "    query = input(\"> \")\n",
    "    # V√©rification si l'utilisateur veut quitter\n",
    "    if query in exit_conditions:\n",
    "        break\n",
    "    # R√©cup√©ration de la m√©t√©o pour un pays donn√©\n",
    "    elif query.startswith(\"chnowa ta9s fi \"):\n",
    "        # R√©cup√©ration du nom du pays\n",
    "        country = query.replace(\"chnowa ta9s fi \", \"\")\n",
    "        # R√©cup√©ration de la m√©t√©o pour le pays\n",
    "        weather = get_weather(country)\n",
    "        print(f\"ta9s: {weather}\")\n",
    "    # Recherche de la d√©finition d'un sujet donn√© sur Wikipedia\n",
    "    elif query.startswith(\"wiki \"):\n",
    "        topic=query.replace(\"wiki \",\"\")\n",
    "        wiki=search_wikipedia(topic)\n",
    "        print(wiki)\n",
    "    # R√©cup√©ration des derni√®res actualit√©s sur un sujet donn√©\n",
    "    elif query.startswith(\"e5er a5bar aala \"):\n",
    "        # R√©cup√©ration du sujet\n",
    "        theme=query.replace(\"e5er a5bar aala \",\"\")\n",
    "        # R√©cup√©ration des derni√®res actualit√©s\n",
    "        top_headlines = newsapi.get_everything(q=theme, sort_by='relevancy',language='ar')\n",
    "        for article in top_headlines['articles']:\n",
    "            print(article['title'])\n",
    "    # Si aucune des commandes ci-dessus n'a √©t√© reconnue, le chatbot tente de r√©pondre\n",
    "    else:\n",
    "        #print(f\"ü§ñ {str(chatbot.get_response(query))}\")\n",
    "\n",
    "        # Ajouter le prompt √† la liste des phrases\n",
    "        sentences.append(query)\n",
    "        \n",
    "        # Initialiser le vecteur TfidfVectorizer pour extraire les caract√©ristiques des phrases\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        \n",
    "        # Cr√©er une matrice Tfidf √† partir des phrases\n",
    "        tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "        \n",
    "        # Convertir la matrice en liste de listes\n",
    "        tfidf_list = tfidf_matrix.todense().tolist()\n",
    "        \n",
    "        # Cr√©er un DataFrame pandas √† partir de la liste de listes\n",
    "        df = pd.DataFrame(tfidf_list, columns=vectorizer.get_feature_names())\n",
    "        \n",
    "        # Calculer la similarit√© cosinus entre le prompt et chaque phrase dans la matrice\n",
    "        cosine_similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])\n",
    "        \n",
    "        # Trier les similarit√©s cosinus dans l'ordre d√©croissant\n",
    "        similarity_list = cosine_similarities.flatten()\n",
    "        index = similarity_list.argsort()[::-1]\n",
    "        \n",
    "        # Trouver l'entr√©e de corpus la plus similaire\n",
    "        most_similar_sentence = sentences[index[0]+1]\n",
    "        \n",
    "        # Ajouter la r√©ponse √† la liste des phrases\n",
    "        sentences.append(most_similar_sentence)\n",
    "        \n",
    "        # Afficher la r√©ponse la plus similaire\n",
    "        print(f\"ü§ñ {str(most_similar_sentence)}\")   \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
