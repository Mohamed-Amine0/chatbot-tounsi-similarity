{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a2a535",
   "metadata": {},
   "source": [
    "# Importation des modules nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a34dd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatterbot import ChatBot\n",
    "from chatterbot.trainers import ListTrainer\n",
    "from cleaner import clean_corpus\n",
    "from weather import get_weather\n",
    "from wikipediaprocess import search_wikipedia\n",
    "from newsapi import NewsApiClient\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105bed87",
   "metadata": {},
   "source": [
    "# Initialisation de l'API de news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4bfd91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsapi = NewsApiClient(api_key='a1d8789da28b4df282afbabff793c211')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fc15d0",
   "metadata": {},
   "source": [
    "# Initialisation du chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5f1298c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Mohamed-Amine-\n",
      "[nltk_data]     Miladi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Mohamed-Amine-\n",
      "[nltk_data]     Miladi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Mohamed-Amine-\n",
      "[nltk_data]     Miladi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "chatbot = ChatBot(\"Chatbot tounsi\",logic_adapters=[      \n",
    "    # Adapter pour évaluer des expressions mathématiques\n",
    "    {\n",
    "        'import_path': 'chatterbot.logic.MathematicalEvaluation',\n",
    "    },\n",
    "    # Adapter pour trouver la meilleure réponse en fonction du contexte\n",
    "    {\n",
    "        'import_path': 'chatterbot.logic.BestMatch',\n",
    "    }\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9645ca7",
   "metadata": {},
   "source": [
    "# Fichier contenant la conversation à utiliser pour entraîner le chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c08e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_FILE=\"chat2.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04e9f67",
   "metadata": {},
   "source": [
    "# Entraînement du chatbot sur le fichier de corpus nettoyé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58b7e86a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Trainer: [####################] 100%\n"
     ]
    }
   ],
   "source": [
    "trainer = ListTrainer(chatbot)\n",
    "cleaned_corpus=clean_corpus(CORPUS_FILE)\n",
    "trainer.train(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48a777b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://play.mobilelegends.com/events/halloweencards/?Yz00WVdzMUtYSnJaMkZhb09WYUdhWFU1RldxZEhTeUh2SldaNkdhcE5va3BscVo1dG1oN0VOJm89d2hhdHNhcHA=',\n",
       " 'Ahla bik',\n",
       " 'Salut',\n",
       " 'Winek cv?',\n",
       " 'Cv hamdoullah',\n",
       " 'Wenti?',\n",
       " 'Labes labes',\n",
       " 'Chkoun aandek a7sen jam3eya mtaa foot?',\n",
       " 'Real madrid wenti?',\n",
       " 'Bayern',\n",
       " 'Behi ta9s lyoum?',\n",
       " 'Ey behi',\n",
       " 'Samili 3 bolden yabdew bel T',\n",
       " 'Tunisie, Tanzanie Tchad',\n",
       " 'Maalem bravo👏',\n",
       " 'Merci🥰',\n",
       " 'Messi wala ronaldo?',\n",
       " 'Ronaldo',\n",
       " 'Bresil wala almania?',\n",
       " 'Bresil fel koora Almania fel 3icha 😉',\n",
       " 'Pizza wala lasagna',\n",
       " 'Pizzaaaa 🍕🍕🍕🍕',\n",
       " 'Capitale mta tunisie chnowa?',\n",
       " 'Tunis',\n",
       " '👏',\n",
       " 'Ch9awlek fel fst ka fac?',\n",
       " 'A9wa fac fi tounes',\n",
       " 'Akther bled t7eb temchilha ?',\n",
       " 'Autriche ma7leha❤ te3jebni barcha',\n",
       " 'Mchit Paris 9bal?',\n",
       " 'Non ma mchitech',\n",
       " 'A7sen repas tounsi aandek?',\n",
       " 'Chorba frik w kafteji',\n",
       " 'Chnowa rayek fel AI?',\n",
       " 'Ai heya lmosta9bel',\n",
       " 'Ai bech te7tal el 3allem',\n",
       " 'A9wa film tfrajet fih ?',\n",
       " 'Ye3bouni aflem fima batman w lord of the rings',\n",
       " 'Taaref tcodi?',\n",
       " 'Ey tawa hehda klem ?',\n",
       " 'A7kili nokta',\n",
       " 'Fech testana men cha3b ychouf darhom mnadhma yes2elhom : ye5i chkoun jey hahaha',\n",
       " 'A7kili nokta',\n",
       " 'Fam djeja ordhet bes5ana ye5i jebet aadhma masmouta',\n",
       " 'A7kili nokta',\n",
       " 'We7ed mbala3 fel embouteillage double mara loula..double marra thenya ye5i tardouh 😂',\n",
       " 'Fi tounes fa9at tal9a we7ed aandou monguela ,kif tes2lou aal wa9t yejbed telifounou 😆',\n",
       " 'Nokta o5ra',\n",
       " 'Fama We7ed kathrelha mel torbia may7el frigidaire ken ma ydo9 lbeb',\n",
       " 'Chnowa aasmet libya?',\n",
       " 'Tripoli',\n",
       " 'Chesmek ?',\n",
       " 'Esmi chatbot tounsi',\n",
       " 'Aya n5alik sadi9i',\n",
       " 'Bye',\n",
       " 'Beslema')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef477f38",
   "metadata": {},
   "source": [
    "# Créer une liste de phrases nettoyées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55423098",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = cleaned_corpus[1:]\n",
    "sentences = list(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8413a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5d25bb5",
   "metadata": {},
   "source": [
    "# Conditions pour quitter le chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "501dff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_conditions = (\":q\", \"quit\", \"exit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916cbb82",
   "metadata": {},
   "source": [
    "# Exécution du ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb0c4ce2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "Pour obtenir la météo d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les dernières actualités sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la définition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> cv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed-Amine-Miladi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Cv hamdoullah\n",
      "*********************************************************\n",
      "Pour obtenir la météo d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les dernières actualités sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la définition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> tcodi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed-Amine-Miladi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Ey tawa hehda klem ?\n",
      "*********************************************************\n",
      "Pour obtenir la météo d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les dernières actualités sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la définition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> chnowa ta9s fi Tunis\n",
      "ta9s: 🤖Fi Tunis aana temperature :21.1 °C wel humidité : 55%.\n",
      "*********************************************************\n",
      "Pour obtenir la météo d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les dernières actualités sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la définition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> e5er a5bar aala Trump\n",
      "ترامب يصل إلى محكمة مانهاتن حيث يمثل أمام القضاء في سابقة تاريخية\n",
      "بعد توجيه 34 اتهاما جنائيا له… ما هو مستقبل ترامب قانونيا وسياسيا؟\n",
      "ترامب قبل محاكمته: لا يمكنهم شرائي وأمريكا أصبحت دولة من العالم الثالث... فيديو\n",
      "*********************************************************\n",
      "Pour obtenir la météo d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les dernières actualités sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la définition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> film ?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed-Amine-Miladi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Ye3bouni aflem fima batman w lord of the rings\n",
      "*********************************************************\n",
      "Pour obtenir la météo d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les dernières actualités sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la définition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> bye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed-Amine-Miladi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Beslema\n",
      "*********************************************************\n",
      "Pour obtenir la météo d'un pays, tapez : chnowa ta9s fi + nom du pays\n",
      "Pour obtenir les dernières actualités sur un sujet, tapez : e5er a5bar aala + sujet\n",
      "Pour obtenir la définition d'un sujet, tapez : wiki + sujet\n",
      "Pour quitter, tapez : quit ou exit\n",
      "************************************************************\n",
      "> :q\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Affichage des instructions pour l'utilisateur\n",
    "    print(\"*********************************************************\\nPour obtenir la météo d'un pays, tapez : chnowa ta9s fi + nom du pays\\nPour obtenir les dernières actualités sur un sujet, tapez : e5er a5bar aala + sujet\\nPour obtenir la définition d'un sujet, tapez : wiki + sujet\\nPour quitter, tapez : quit ou exit\\n************************************************************\")\n",
    "    # Lecture de l'entrée utilisateur\n",
    "    query = input(\"> \")\n",
    "    # Vérification si l'utilisateur veut quitter\n",
    "    if query in exit_conditions:\n",
    "        break\n",
    "    # Récupération de la météo pour un pays donné\n",
    "    elif query.startswith(\"chnowa ta9s fi \"):\n",
    "        # Récupération du nom du pays\n",
    "        country = query.replace(\"chnowa ta9s fi \", \"\")\n",
    "        # Récupération de la météo pour le pays\n",
    "        weather = get_weather(country)\n",
    "        print(f\"ta9s: {weather}\")\n",
    "    # Recherche de la définition d'un sujet donné sur Wikipedia\n",
    "    elif query.startswith(\"wiki \"):\n",
    "        topic=query.replace(\"wiki \",\"\")\n",
    "        wiki=search_wikipedia(topic)\n",
    "        print(wiki)\n",
    "    # Récupération des dernières actualités sur un sujet donné\n",
    "    elif query.startswith(\"e5er a5bar aala \"):\n",
    "        # Récupération du sujet\n",
    "        theme=query.replace(\"e5er a5bar aala \",\"\")\n",
    "        # Récupération des dernières actualités\n",
    "        top_headlines = newsapi.get_everything(q=theme, sort_by='relevancy',language='ar')\n",
    "        for article in top_headlines['articles']:\n",
    "            print(article['title'])\n",
    "    # Si aucune des commandes ci-dessus n'a été reconnue, le chatbot tente de répondre\n",
    "    else:\n",
    "        #print(f\"🤖 {str(chatbot.get_response(query))}\")\n",
    "\n",
    "        # Ajouter le prompt à la liste des phrases\n",
    "        sentences.append(query)\n",
    "        \n",
    "        # Initialiser le vecteur TfidfVectorizer pour extraire les caractéristiques des phrases\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        \n",
    "        # Créer une matrice Tfidf à partir des phrases\n",
    "        tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "        \n",
    "        # Convertir la matrice en liste de listes\n",
    "        tfidf_list = tfidf_matrix.todense().tolist()\n",
    "        \n",
    "        # Créer un DataFrame pandas à partir de la liste de listes\n",
    "        df = pd.DataFrame(tfidf_list, columns=vectorizer.get_feature_names())\n",
    "        \n",
    "        # Calculer la similarité cosinus entre le prompt et chaque phrase dans la matrice\n",
    "        cosine_similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])\n",
    "        \n",
    "        # Trier les similarités cosinus dans l'ordre décroissant\n",
    "        similarity_list = cosine_similarities.flatten()\n",
    "        index = similarity_list.argsort()[::-1]\n",
    "        \n",
    "        # Trouver l'entrée de corpus la plus similaire\n",
    "        most_similar_sentence = sentences[index[0]+1]\n",
    "        \n",
    "        # Ajouter la réponse à la liste des phrases\n",
    "        sentences.append(most_similar_sentence)\n",
    "        \n",
    "        # Afficher la réponse la plus similaire\n",
    "        print(f\"🤖 {str(most_similar_sentence)}\")   \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
